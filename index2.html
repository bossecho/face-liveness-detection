<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Real Face Detector</title>
  <script src="https://cdn.tailwindcss.com"></script>
  
</head>
<body class="flex items-center justify-center h-screen bg-gray-900 text-white">
<div class="p-6 bg-gray-800 rounded-xl shadow-lg text-center">
  <h1 class="text-xl font-bold mb-4">Real Face Detector</h1>
  
  <div class="relative inline-block">
    <!-- Video -->
    <video id="video" autoplay muted playsinline 
      class="rounded-xl border border-gray-700 w-80 h-60"></video>
    
    <!-- Transparent overlay canvas -->
    <canvas id="overlay" 
      class="absolute top-0 left-0 rounded-xl w-80 h-60 pointer-events-none"></canvas>
  </div>

  <!-- Status message -->
  <p id="status" class="mt-4 text-green-400 font-semibold">Loading...</p>
</div>


   <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>


<script>
const video = document.getElementById("video");
const statusEl = document.getElementById("status");

async function startCamera() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
    video.srcObject = stream;
  } catch (err) {
    statusEl.textContent = "âŒ Camera not accessible";
    statusEl.className = "mt-4 text-red-400 font-bold";
  }
}

async function init() {
  await faceapi.nets.tinyFaceDetector.loadFromUri("./models");
  await faceapi.nets.faceLandmark68Net.loadFromUri("./models");

  await startCamera();

  video.addEventListener("play", () => {
    const canvas = document.getElementById("overlay");
    const ctx = canvas.getContext("2d");

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    const options = new faceapi.TinyFaceDetectorOptions({
      inputSize: 416,
      scoreThreshold: 0.3
    });

    let blinkCounter = 0;
    let blinked = false;

    async function detectLoop() {
      const result = await faceapi
        .detectSingleFace(video, options)
        .withFaceLandmarks();

      ctx.clearRect(0, 0, canvas.width, canvas.height);

      if (result) {
        const resized = faceapi.resizeResults(result, {
          width: video.videoWidth,
          height: video.videoHeight
        });

        faceapi.draw.drawDetections(canvas, [resized]);
        faceapi.draw.drawFaceLandmarks(canvas, [resized]);

        const lm = resized.landmarks;
        const leftEye = lm.getLeftEye();
        const rightEye = lm.getRightEye();

        const blink = isBlinking(leftEye) || isBlinking(rightEye);

        if (blink) {
          blinkCounter++;
        } else {
          if (blinkCounter > 2 && !blinked) { 
            // âœ… require ~3 frames of closed eyes
            alert("âœ… Blink detected!");
            blinked = true;
          }
          blinkCounter = 0;
          blinked = false;
        }
      }

      requestAnimationFrame(detectLoop);
    }

    detectLoop();
  });
}

function euclideanDistance(p1, p2) {
  return Math.hypot(p1.x - p2.x, p1.y - p2.y);
}

function isBlinking(eye) {
  const vertical1 = euclideanDistance(eye[1], eye[5]);
  const vertical2 = euclideanDistance(eye[2], eye[4]);
  const horizontal = euclideanDistance(eye[0], eye[3]);

  const EAR = (vertical1 + vertical2) / (2.0 * horizontal);
  return EAR < 0.21; // ðŸ‘ˆ adjust threshold
}

init();
</script>


















</body>
</html>
